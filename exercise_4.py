# -*- coding: utf-8 -*-
"""ML_Homework-4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FnRcidbdU-_LHMhy6uQxhaZyfzuXFQ4o
"""

# Task-1: LP

import pandas as pd

train_data = pd.read_csv('/content/ZipDigits.train')
test_data = pd.read_csv('/content/ZipDigits.test')

import numpy as np
import matplotlib.pyplot as plt

# Load the data from the file
with open('ZipDigits.train', 'r') as file:
    lines = file.readlines()

# empty lists to store data
labels = []
features = []

# Filter and preprocess the data
for line in lines:
    data = line.strip().split()
    label = int(float(data[0]))
    labels.append(1 if label == 1 else -1)
    feature_values = [float(val) for val in data[1:]]
    features.append(feature_values)

# Convert to NumPy arrays
labels = np.array(labels)
features = np.array(features)

# intensity and symmetry functions
def intensity(image):
    return np.sum(image)

def symmetry(image):
    half_len = len(image) // 2
    left_half = image[:half_len]
    right_half = image[half_len:]
    left_avg = np.mean(left_half)
    right_avg = np.mean(right_half)
    return abs(left_avg - right_avg)

# intensity and symmetry features for each data point
intensity_features = np.apply_along_axis(intensity, axis=1, arr=features)
symmetry_features = np.apply_along_axis(symmetry, axis=1, arr=features)

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Assuming intensity_features and symmetry_features are already defined

# Combine intensity and symmetry features
X = np.column_stack((intensity_features, symmetry_features))

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)

# Create an SVM classifier
svm_classifier = SVC(kernel='linear')  # You can experiment with different kernels

# Train the classifier
svm_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = svm_classifier.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")

import numpy as np
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Assuming intensity_features and symmetry_features are already defined

# Combine intensity and symmetry features
X = np.column_stack((intensity_features, symmetry_features))

# Labels are already defined

# Create SVM classifiers with different kernels
linear_svm = SVC(kernel='linear')
poly_svm = SVC(kernel='poly', degree=3)
rbf_svm = SVC(kernel='rbf')

# Train the classifiers
linear_svm.fit(X, labels)
poly_svm.fit(X, labels)
rbf_svm.fit(X, labels)

# Make predictions on the training set
y_pred_linear = linear_svm.predict(X)
y_pred_poly = poly_svm.predict(X)
y_pred_rbf = rbf_svm.predict(X)

# Calculate training accuracy
accuracy_linear = accuracy_score(labels, y_pred_linear)
accuracy_poly = accuracy_score(labels, y_pred_poly)
accuracy_rbf = accuracy_score(labels, y_pred_rbf)

# Report training accuracy
print(f"Training Accuracy (Linear Kernel): {accuracy_linear * 100:.2f}%")
print(f"Training Accuracy (Polynomial Kernel): {accuracy_poly * 100:.2f}%")
print(f"Training Accuracy (RBF Kernel): {accuracy_rbf * 100:.2f}%")

# Task-2 LP1

import numpy as np
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Assuming intensity_features and symmetry_features are already defined

# Combine intensity and symmetry features
X = np.column_stack((intensity_features, symmetry_features))

# Labels are already defined

# Split the data into training and testing sets
X_train, X_val, y_train, y_val = train_test_split(X, labels, test_size=0.2, random_state=42)

# Define the parameter grid
param_grid = {'C': [0.01, 0.1, 1, 10, 100],
              'kernel': ['linear', 'poly', 'rbf'],
              'degree': [3]}  # 3rd order polynomial kernel

# Create an SVM classifier
svm_classifier = SVC()

# Create the GridSearchCV object
grid_search = GridSearchCV(svm_classifier, param_grid, cv=5, scoring='accuracy')

# Fit the GridSearchCV object to the training data
grid_search.fit(X_train, y_train)

# Get the best parameters
best_params = grid_search.best_params_

# Train the SVM classifier with the best parameters on the entire training set
best_svm_classifier = SVC(**best_params)
best_svm_classifier.fit(X_train, y_train)

# Make predictions on the validation set
y_pred_val = best_svm_classifier.predict(X_val)

# Calculate validation accuracy
accuracy_val = accuracy_score(y_val, y_pred_val)

# Report results
print(f"Best Parameters: {best_params}")
print(f"Validation Accuracy: {accuracy_val * 100:.2f}%")

import numpy as np
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Assuming intensity_features and symmetry_features are already defined

# Combine intensity and symmetry features
X = np.column_stack((intensity_features, symmetry_features))

# Labels are already defined

# Split the data into training and testing sets
X_train, X_val, y_train, y_val = train_test_split(X, labels, test_size=0.2, random_state=42)

# Define the parameter grid
param_grid = {'C': [0.01, 0.1, 1, 10, 100],
              'kernel': ['linear', 'poly', 'rbf'],
              'degree': [3]}  # 3rd order polynomial kernel

# Create an SVM classifier
svm_classifier = SVC()

# Create the GridSearchCV object
grid_search = GridSearchCV(svm_classifier, param_grid, cv=5, scoring='accuracy')

# Fit the GridSearchCV object to the training data
grid_search.fit(X_train, y_train)

# Get the cross-validation results
cv_results = grid_search.cv_results_

# Report cross-validation error for each combination of kernel and C value
for mean_score, params in zip(cv_results['mean_test_score'], cv_results['params']):
    print(f"Parameters: {params}, Cross-Validation Accuracy: {mean_score * 100:.2f}%")

# HP1

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Assuming intensity_features and symmetry_features are already defined

# Combine intensity and symmetry features
X = np.column_stack((intensity_features, symmetry_features))

# Labels are already defined

# Split the data into training and testing sets
X_train, X_val, y_train, y_val = train_test_split(X, labels, test_size=0.2, random_state=42)

# Define the parameter grid
param_grid = {'C': [0.01, 0.1, 1, 10, 100],
              'kernel': ['linear', 'poly', 'rbf'],
              'degree': [3]}  # 3rd order polynomial kernel

# Create an SVM classifier
svm_classifier = SVC()

# Create the GridSearchCV object
grid_search = GridSearchCV(svm_classifier, param_grid, cv=5, scoring='accuracy')

# Fit the GridSearchCV object to the training data
grid_search.fit(X_train, y_train)

# Get the cross-validation results
cv_results = grid_search.cv_results_

# Reshape mean_test_score to a 2D array for heatmap plotting
heatmap_data = np.array(cv_results['mean_test_score']).reshape(len(param_grid['kernel']), -1)

# Plot heatmap for cross-validation error
plt.figure(figsize=(10, 6))
sns.heatmap(heatmap_data, annot=True, fmt=".3f", cmap="YlGnBu", xticklabels=param_grid['C'], yticklabels=param_grid['kernel'])
plt.title('Cross-Validation Accuracy for Different Kernels and C Values')
plt.xlabel('C Value')
plt.ylabel('Kernel')

# Add caption as text
caption_text = (



"\nThe in-sample error, or training accuracy, is 93.96%.\n"
"This value indicates that the SVM classifier, trained on the entire\n"
"training set with the hyperparameters selected through cross-validation,\n"
"correctly predicted the labels for approximately 93.96% of the training instances.\n"
" Since the accuracy is high on the training dataset, it doesn't necessarily guarantee\n"
"good generalization on the test data. Once the model is run on the test data,\n"
"It's reliable to estimate its performance.\n"



)
plt.figtext(0.5, -0.05, caption_text, ha="center", va="center", fontsize=10, wrap=True)


plt.show()

# Train the SVM classifier with the best parameters on the entire training set
best_svm_classifier = SVC(**grid_search.best_params_)
best_svm_classifier.fit(X_train, y_train)

# Make predictions on the training set
y_pred_train = best_svm_classifier.predict(X_train)

# Calculate training accuracy
accuracy_train = accuracy_score(y_train, y_pred_train)

# Report in-sample error
print(f"In-Sample Error (Training Accuracy): {accuracy_train * 100:.2f}%")

# Task-3 LP1

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Assuming intensity_features and symmetry_features are already defined

# Combine intensity and symmetry features
X = np.column_stack((intensity_features, symmetry_features))

# Labels are already defined

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)

# Define the best parameters obtained from cross-validation
best_params = {'C': 1, 'kernel': 'linear', 'degree': 3}  # Replace with the actual best parameters

# Create the final SVM classifier with the best parameters
final_svm_classifier = SVC(**best_params)

# Train the final classifier on the entire training set
final_svm_classifier.fit(X_train, y_train)

# Make predictions on the training set
y_pred_train = final_svm_classifier.predict(X_train)

# Calculate training accuracy
accuracy_train = accuracy_score(y_train, y_pred_train)

# Report in-sample error
print(f"In-Sample Error (Training Accuracy): {accuracy_train * 100:.2f}%")

# LP2

import numpy as np
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Load the test data from the file
with open('ZipDigits.test', 'r') as file:
    test_lines = file.readlines()

# empty lists to store test data
test_labels = []
test_features = []

# Preprocess the test data
for line in test_lines:
    data = line.strip().split()
    label = int(float(data[0]))
    test_labels.append(1 if label == 1 else -1)
    feature_values = [float(val) for val in data[1:]]
    test_features.append(feature_values)

# Convert to NumPy arrays
test_labels = np.array(test_labels)
test_features = np.array(test_features)

# Assuming intensity and symmetry functions are defined as before
intensity_test = np.apply_along_axis(intensity, axis=1, arr=test_features)
symmetry_test = np.apply_along_axis(symmetry, axis=1, arr=test_features)

# Combine intensity and symmetry features for the test set
X_test = np.column_stack((intensity_test, symmetry_test))

# Create the final SVM classifier with the best parameters
final_svm_classifier = SVC(**best_params)

# Train the final classifier on the entire training set
final_svm_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred_test = final_svm_classifier.predict(X_test)

# Calculate test accuracy
accuracy_test = accuracy_score(test_labels, y_pred_test)

# Report test error
print(f"Test Error (Test Accuracy): {accuracy_test * 100:.2f}%")

# Task-4 HP1

import matplotlib.pyplot as plt

# Model names
models = ['PLA', 'Pocket', 'Pocket (3rd Order)', 'Neural Network', 'SVM']

# Test accuracies
test_accuracies = [36.79, 58.74, 58.74, 95.28, 93.42]  # Replace with actual test accuracies

# Plotting
plt.figure(figsize=(10, 6))
plt.bar(models, test_accuracies, color=['green', 'red', 'orange', 'blue', 'purple'])
plt.ylim(0, 100)
plt.title('Test Accuracies of Different Models')
plt.xlabel('Models')
plt.ylabel('Test Accuracy (%)')
plt.show()