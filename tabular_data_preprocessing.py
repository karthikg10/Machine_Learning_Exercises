# -*- coding: utf-8 -*-
"""Tabular data preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MVi_Ph20AmmRsMAn22HadazJc0MZljLF
"""



import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import cross_val_score

# Load the data
data = pd.read_csv("/content/drive/MyDrive/training_wids2024C1.csv")

# Separate numerical and categorical columns
numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns
categorical_cols = data.select_dtypes(include=['object']).columns

# Preprocessing for numerical data
imputer = SimpleImputer(strategy='mean')
data[numerical_cols] = imputer.fit_transform(data[numerical_cols])

# Preprocessing for categorical data
encoder = LabelEncoder()
for col in categorical_cols:
    data[col] = encoder.fit_transform(data[col])

# Split the data into features and target variable
X = data.drop("DiagPeriodL90D", axis=1)
y = data["DiagPeriodL90D"]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature Scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Apply PCA
pca = PCA(n_components=0.95)  # Keep 95% of variance
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

# Model Building and Evaluation
models = {
    "Logistic Regression": LogisticRegression(),
    "Random Forest": RandomForestClassifier(),
    "SVM": SVC()
}

for name, model in models.items():
    model.fit(X_train_pca, y_train)
    y_pred = model.predict(X_test_pca)
    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred)
    print(f"Model: {name}")
    print(f"Accuracy: {accuracy}")
    print(f"Classification Report:\n{report}")
    print("="*50)

import matplotlib.pyplot as plt

# Accuracy scores with PCA
accuracy_with_pca = [0.7912, 0.7758, 0.7878]

models = ['Logistic Regression', 'Random Forest', 'SVM']

plt.figure(figsize=(10, 6))
plt.bar(models, accuracy_with_pca, color='skyblue')
plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.title('Model Accuracy with PCA')
plt.ylim(0.75, 0.8)
plt.show()



"""Logistic Regression:
Mean CV Accuracy: 0.784
Random Forest:
Mean CV Accuracy: 0.774
Support Vector Machine (SVM):
Mean CV Accuracy: 0.779
These scores represent the average accuracy of each model across different folds of the training data.
Generally, they are consistent with the accuracy values obtained from the initial train-test split.

Based on these results, all three models perform similarly in terms of mean accuracy.
"""